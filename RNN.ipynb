{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 09:27:09.791622: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import timeseries_dataset_from_array\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from MultiSeriesWindowsGenerator import MultiSeriesWindowsGenerator\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_row\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for i in range(0, 27):\n",
    "    df = pd.read_csv(f\"data/aggregated_individual_data_interpolation/interpolation/{i}_interpolated.csv\",\n",
    "                     index_col=0)\n",
    "    df = pd.read_csv(f\"data/aggregated_individual_data_interpolation/interpolation/{i}_interpolated.csv\",\n",
    "                     index_col=0)\n",
    "    df[\"subject_id\"] = i + 1\n",
    "    data_list.append(df)\n",
    "\n",
    "# Concatenate the data into a single dataset\n",
    "data = pd.concat(data_list)\n",
    "data.drop([\"circumplex.arousal_std\", \"circumplex.valence_std\", \"mood_std\", \"activity_std\"], inplace=True, axis=1)\n",
    "\n",
    "use_date = 0\n",
    "\n",
    "if use_date:\n",
    "    data.drop([\"date\"], inplace=True, axis=1)\n",
    "    date_time = pd.to_datetime(data.pop('date'))\n",
    "    df = data\n",
    "    df['days'] = date_time\n",
    "\n",
    "else:  # use days from day 0 of recording\n",
    "    data.drop([\"date\"], inplace=True, axis=1)\n",
    "    df = data\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df = df.astype({'subject_id': 'float64', 'days': 'float64', 'weekday': 'float64'})\n",
    "df = data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "weekday                   int64\nmood                    float64\ncircumplex.arousal      float64\ncircumplex.valence      float64\nactivity                float64\nscreen                  float64\ncall                    float64\nsms                     float64\nappCat.builtin          float64\nappCat.communication    float64\nappCat.entertainment    float64\nappCat.finance          float64\nappCat.game             float64\nappCat.office           float64\nappCat.other            float64\nappCat.social           float64\nappCat.travel           float64\nappCat.unknown          float64\nappCat.utilities        float64\nappCat.weather          float64\ndays                      int64\nsubject_id                int64\ndtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.dtypes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/all_data_aggr_nonan.csv\", index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "weekday                   int64\nmood                    float64\ncircumplex.arousal      float64\ncircumplex.valence      float64\nactivity                float64\nscreen                  float64\ncall                    float64\nsms                     float64\nappCat.builtin          float64\nappCat.communication    float64\nappCat.entertainment    float64\nappCat.finance          float64\nappCat.game             float64\nappCat.office           float64\nappCat.other            float64\nappCat.social           float64\nappCat.travel           float64\nappCat.unknown          float64\nappCat.utilities        float64\nappCat.weather          float64\nsubject_id                int64\ndays                      int64\ndtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.dtypes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "LABELS = ['mood']\n",
    "REGRESSORS = ['weekday', 'circumplex.arousal', 'circumplex.valence',\n",
    "              'activity', 'screen', 'call', 'sms', 'appCat.builtin',\n",
    "              'appCat.communication', 'appCat.entertainment', 'appCat.finance',\n",
    "              'appCat.game', 'appCat.office', 'appCat.other', 'appCat.social',\n",
    "              'appCat.travel', 'appCat.unknown', 'appCat.utilities', 'appCat.weather']\n",
    "\n",
    "DATE = 'days'  # always correct\n",
    "IN_STEPS = 14  # use 7 days\n",
    "OUT_STEPS = 14  # to predict 1 day in the future\n",
    "GROUPBY = ['subject_id']\n",
    "BATCH_SIZE = 32"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "\n",
    "n = len(df)\n",
    "train_series = df.groupby(GROUPBY, as_index=False, group_keys=False).apply(\n",
    "    lambda x: x.iloc[:int(len(x) * 0.7)]).reset_index(drop=True)\n",
    "val_series = df.groupby(GROUPBY, as_index=False, group_keys=False).apply(\n",
    "    lambda x: x.iloc[int(len(x) * 0.7):int(len(x) * 0.9)]).reset_index(drop=True)\n",
    "test_series = df.groupby(GROUPBY, as_index=False, group_keys=False).apply(\n",
    "    lambda x: x.iloc[int(len(x) * 0.9):]).reset_index(drop=True)\n",
    "\n",
    "test_window = MultiSeriesWindowsGenerator(\n",
    "    input_width=IN_STEPS, label_width=OUT_STEPS, shift=1, batch_size=BATCH_SIZE, GROUPBY=GROUPBY,\n",
    "    label_columns=LABELS, regressor_columns=REGRESSORS, DATE=DATE, LABELS=LABELS)\n",
    "\n",
    "test_window.update_datasets(train_series, val_series, test_series, norm=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# lstm_model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.LSTM(128, return_sequences=True,activation=\"relu\"),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.LSTM(128, return_sequences=False, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(units=1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.001))\n",
    "# ])\n",
    "\n",
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "MAX_EPOCHS = 20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def compile_and_fit(model, window, patience=2):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                      patience=patience,\n",
    "                                                      mode='min')\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1),\n",
    "                  metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                        validation_data=window.val,\n",
    "                        callbacks=[early_stopping])\n",
    "    return history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "21/21 [==============================] - 8s 135ms/step - loss: 0.2573 - mean_absolute_error: 0.3154 - val_loss: 1.8527 - val_mean_absolute_error: 0.9887\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - 3s 75ms/step - loss: 0.2436 - mean_absolute_error: 0.3060 - val_loss: 1.9531 - val_mean_absolute_error: 1.0205\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - 3s 62ms/step - loss: 0.2357 - mean_absolute_error: 0.3033 - val_loss: 2.0176 - val_mean_absolute_error: 1.0376\n",
      "12/12 [==============================] - 3s 20ms/step - loss: 2.0176 - mean_absolute_error: 1.0376\n"
     ]
    }
   ],
   "source": [
    "history = compile_and_fit(lstm_model, test_window)\n",
    "val_performance = {}\n",
    "performance = {}\n",
    "val_performance['LSTM'] = lstm_model.evaluate(test_window.val)\n",
    "performance['LSTM'] = lstm_model.evaluate(test_window.test, verbose=0)\n",
    "\n",
    "test_window.plot(lstm_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Autoregressive RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}